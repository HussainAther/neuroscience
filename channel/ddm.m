%% simpleDDMtutorial (simple drift diffusion model)

%% Preliminaries. Paths and test data
%%
% Change the matlab path to the ddm_tutorial directory
%%
% From the ddm_tutorial directory, please add the following to your path
addpath(genpath("mytools"))
addpath collapsing_bound

%%
% Load either test_data.mat or collapse_data.mat. The former is real human
% data from a  perceptual decision-making task in which a human observer
% made left vs. right decisions about the net direction of dynamic random
% dot motion. The latter was generated by simulating a model with a
% collapsing bound. Comment or uncomment one of the following
%

% choose data_test or collapse_data
%
% load data_test 
load collapse_data.mat

display(D) % examine the data structure

%% The data structure 
% Each trial is associated with a stimulus strength, a
% choice and a reaction time. 
%% 
% *D  is a structure containing the information for all trials*
%%
% * D.strength  stimulus strength with the sign indicating the direction
% * D.rt 	    reaction time in seconds
% * D.choice    choice 0 or 1, being correct for negative and positive strengths, respectively 
%
% Notice that the data file contains individual trials. The fitting assigns
% each trial a likelihood even though the expectations (and standard
% deviation) derive from grouped statistics.
ntrials = length(D.strength) % number of trials
 
%%
% The stimulus *strength* can be any real number. For motion, there are
% typically just a few unique values. Other data sets might employ a
% unique value for each signed strength. This is fine for the fitting
% routines below, but some of the routines for displaying the data require
% minor modification (see below).

%%
theStrengths = unique(D.strength);
 
%%
% A choice coded as 1 is correct if D.strength(i)>0, and error if
% D.strength(i)<0. The user can decide what do with data when
% D.strength==0. The choice field shows what the subject did, not whether
% it was correct. There is no "correct" field in D. Typically, the choices
% will be mixed because the subjects make errors. When the strengths is 0,
% we expect that the choices will be evenly split (on average) unless
% there's a bias. For a given strength we expect the actual split follows
% a binomial distribution.


%% Part 1. Simplest diffusion model
% This model assumes that the evidence starts from a delta function at 0
% and accumulates until it hits one of two symmetric, stationary bounds at
% $\pm B$, and that the drift rate is proportional to stimulus strength
% (with proportionality constant $\kappa$). Furthermore, it assumes that
% bias, if  there is one, is equivalent to a shift in the choice function
% along the stimulus strength axis (i.e., a bias in the drift). We next
% explain the rationale for these assumptions in the motion task:
%
% *Assumption 1.* Drift rate is proportional to strength. 
%
% This is actually three assumptions, each of which is wrong, but not
% horribly so, even in the best of circumstances (e.g., RDM experiments).
% The process is an accumulation (or integral) of samples of momentary
% evidence, with expectation $\left\langle{ f(C) \Delta t}\right\rangle$, where C is
% stimulus strength. The variance of the momentary evidence is
% $\sigma^2(C)\Delta t$. Thus $f(C)$ is the expectation of the excess
% evidence in favor of the positive choice at 1 sec, were there no bounds,
% and $\sigma^2(C)$ is the variance of this same accumulation at 1 second.
% Note that the drift rate is also an expectation, $f(C)$, not a best
% fitting line to a a diffusion path. It does not change from trial to
% trial unless the expectation of the momentary evidence were to change
% (e.g., a different stimulus strength). Of course the momentary evidence
% is different from sample to sample, giving rise to a random walk (or
% diffusion path) that will not be identical from decision to decision
% (experimental trial to trial), but that does not imply that the drift
% rate is different, just as each random sample of momentary evidence does
% not imply a change in the mean.
%%
% The assumption that drift rate is proportional to stimulus strength
% comprises 3 _sub-assumptions_. The first (*1a*) is that the expectation of
% the momentary evidence is zero when $C=0$, and as discussed in
% *assumption 2*, we accommodate this exception with an offset to the
% momentary evidence (i.e., drift rate). The second (*1b*)is that the mean
% of the momentary evidence (hence drift rate) is proportional to stimulus
% strength. The rationale for this simplification is worthy of scrutiny
% because it is unlikely to apply in many circumstances. In the motion
% task, however, it is thought that the samples of evidence derive from
% populations of direction selective neurons in area MT/V5. Rightward
% preferring MT neurons respond to C=0 motion at around 20 spikes per
% second (sp/s) and increase their firing rate linearly, on average, as a
% function of $|C|$ when motion is in their preferred direction. They also
% decrease their firing rates linearly (from the C=0 level) as a function
% of increasing $|C|$ when motion is in the opposite direction (e.g.,
% left). If the momentary evidence is the difference in firing rate between
% rightward and leftward preferring neurons, this difference has an
% expectation proportional to C. In other words, it is consistent with
% *1a* and *1b*.
% 
% In general we do not assume *1b* holds. One useful rule of thumb is to
% fit a choice function with logistic regression (GLM) using a bias term
% and stimulus strength. 
% 
% The third sub-assumption (*1c*) concerns the variance, in particular that it
% is independent of stimulus strength. The rationale is an
% oversimplification of the same neurophysiological observations. Briefly,
% neurons are noisy and exhibit generalized-renewal statistics in their
% spike counts, implying that the variance of the spikes counted in an
% epoch is proportion to the mean spike count in this epoch. The constant
% of proportionality would be 1 for a Poisson spiking process, but there is
% not reason to commit to this since we are really conceiving of averages
% of many neurons which are weakly correlated in their noise properties.
% The proportional relationship between mean and variance is retained, such
% that $V=\phi m$ where $m$ represents the mean rate and $\phi$ is Assuming
% left and right preferring ensembles are independent in their noise, the
% variance of the difference between these firing rates is the sum of their
% variances. When C=0, the the mean of the difference is 0 (per *1a*), but
% the variance is the sum of the variances associated with the left and
% right ensembles: $2\phi m_0$, where $m_0$ is the mean response to the C=0,
% which is the same for left and right neurons. If $C>0$, one of the
% ensembles increases its response by an amount proportional to the change
% in firing rate, and the other decreases. If these changes were the same
% size, the sum of the variance would not change from $C=0$
%
% $$ V=\phi (m_0 + \Delta m) + \phi (m_0 - \Delta m) = 2\phi m_0 $$
%
% However, the neurophysiology indicates that the increments are about 3
% times larger than the decrements. This implies that the variance is not a
% constant but should increase linearly with stimulus strength. The
% |dtb_fit_means| function has the capacity to accommodate this variance
% scaling feature. We ignore this wrinkle in the examples below.
%
% If we adopt the assumption *1c*, it leaves open the question of how large
% it should be. Here we are permitted any choice we like, so long as the
% bound _�B_ and the drift rate are to be fitted. For reasons explained
% below, the bound height and the drift rate actually incorporate this
% scaling. We therefore set the variance of the momentary evidence to 
%
% $$ \sigma^2 = \Delta t $$  
%
% consistent with the Wiener process (unit variance in the cumulant at 1
% second). This will be useful when comparing to more elaborate models in
% which we produce (or conceive of) sampling at fine or coarse $\Delta t%.
%
% 
% Together, assumptions *1a-c* lead to a parsimonious representation of the
% drift rate. To understand how, we need to remind ourselves that what we"re
% trying to explain is how often the accumulation of samples of momentary
% evidence will stop at the upper (positive) bound. This is a logistic
% function of the product of two terms
%
% $$ P_{+}= \frac{1}{1 + e^{-2\theta_1 B}}  $$
%
% where _B_ is bound height and $\theta_1$ is the non-trivial root of the
% moment generating function of the distribution of momentary evidence. The
% reason this term shows up has to do with something called Wald"s
% martingale (see Shadlen et al 2006 for a tutorial). For the Gaussian
% distribution (and many others) $\theta_1$ is proportional to the mean
% divided by the variance of this random variable. Assumptions *1b* and
% *1c* allow us to replace $2\theta_1$ with $\kappa C$. Therefore
%
% $$ P_{+}(C) = \frac{1}{1 + e^{-\kappa C B}}  $$
%
% Importantly, if variance were to change as a function of strength, it
% would affect the estimate of $\kappa$ or require replacement of 
% $\kappa C$ by some $f(C)$. These considerations remind us that the
% "drift rate" ought to be affected by noise.
%
% Note that the same $\theta_1$ term also shows up in the expression for
% the mean time of decision termination: (the number of steps to
% reach a bound). However the way it does allows one to separate the terms
% of the product. The intuition is that when the mean of the momentary
% evidence, hence the drift rat, is near zero, the time to the bound is
% determined mainly by the noise (e.g., diffusion), whereas when the drift
% rate is far from zero the time is determined mainly by the mean of the
% momentary evidence (i.e., drift rate). When the drift rate is zero, the
% expected number of samples to reach an upper or lower bound is $B^2$.
% This conforms to a useful intuition. Imagine a particle that takes a step
% to the right or the left with probability $\frac{1}{2}$. The expected
% distance from the origin after _N_ steps is $\sqrt{N}$. 
%  
%
% *Assumption 2. Any choice bias is approximated by an offset to the drift rate*
%
% The drift diffusion model provides two ways to implement a bias for the
% negative or positive choice. The first and more obvious is to start the
% accumulation closer to the favored bound. This is parameterized as a
% starting point offset in the fitting routines; it is the same as
% asymmetric bounds. A starting point offset would seem to make sense
% because the bias is fixed for the duration of the trial and might be
% likened to a simple criterion offset, as in signal detection theory. In
% the SPRT, it is effectively an initial evidence in units of log prior
% odds. For these and other reasons, the strategy seemed to be the obvious
% one. However, in an environment in which one makes decisions from
% evidence that can vary in reliability form one decision to the next, the
% starting point offset is actually counter productive and the bias ought
% to be given more weight as time passes during deliberation. 
%
% The intuition here is that as time goes by and the accumulated evidence
% has not yet reached a bound (or has not meandered far from the starting
% point) it is likely that the source of evidence (the stimulus) is
% unreliable, weak, low signal to noise ratio. If one knows that a stimulus
% is reliable, one ought to place less weight on a bias. Whereas, if one
% knows that the the stimulus is weak, then one ought to exploit a bias.
% Put another way, if it takes more time to acquire the same level of
% evidence in favor of rightward, say, then the odds that a decision in
% favor of rightward will be correct is less than if that amount of evidence
% were acquired in less time. This has been shown in studies of confidence
% in humans and monkeys. The implication for incorporation of bias (e.g., a
% prior probability that motion is more likely rightward) was explained and
% tested in Hanks et al. (2011). It should influence the decision
% negligibly at the beginning of the accumulation and increase leverage as
% time goes on. The shape of this dynamic bias depends on the level of
% possible difficulties (e.g., the prior distribution of stimulus
% strengths), but it is often approximated by a linear function of time,
% and this could be produced by an offset to the drift rate.
%
% Starting point offset and drift offset are not mutually exclusive. A good
% rule of thumb is that a drift offset will dominate when there are many
% difficult conditions and a drift offset will dominate when there are only
% a few. In the random dot motion task, we sample the difficult conditions
% heavily. That"s because we want to encourage integration as a strategy,
% and let"s face it, without an incentive to accumulate many samples of
% evidence, why would one do it? And not to put too fine a point on it, but
% if one is interested in applying or studying integration in time, then it
% makes sense to establish conditions that promote long(ish) integration
% times. We will make a related point in Part 2 when we discuss the
% rationale for collapsing bounds.


%% 1.1 Identify the trials we wish to include for RT
% This step is not part of the fitting per se. It is essential,
% nonetheless, to identify a set of trials that we wish to exclude from the
% fit of reaction time.
% 
% Fit a logistic to the data and express the bias in units of motion
% strength
beta = glmfit(D.strength,D.choice, "binomial", "link", "logit");
strength_bias = -beta(1)/beta(2); %  bias in units of strength 
%% 
% We do not estimate the bias from this logistic. We use it only to figure
% out which choices are effectively errors. By effectively, I mean they are
% in the direction that is opposite the sign of the drift. The simple
% symmetric diffusion model cannot explain the mean RT on these errors. So
% we should not try to fit those data. Same reasoning applies to the shapes
% of the RT distributions. So we don"t try to get that right either. Note
% that bias in our experiment is approximated by a change in drift rate. And
% this is why the classification makes sense. 
% 
% For each trial we set a boolean variable that reflects this inclusion criterion for fitting reaction times
 
D.include_for_rt=(D.strength>= strength_bias & D.choice==1) | (D.strength<= strength_bias & D.choice==0);
  

%% 1.2 Estimate the standard deviation of the RT
% This is another preliminary step before we fit the RT. The fit will
% respect the reliability of the data (see Step 3).
% For the motion task, we have multiple trials at the 
% different strengths. So we can pluck this out in a simple loop.


D.rt_std =nan(size(D.rt));

for i = 1:length(theStrengths)
    s = D.strength==theStrengths(i);
    pCh(i) = mean(D.choice(s)); % prob of choosing the + choice
      
    L = s & D.include_for_rt;
    D.rt_std(L) = std(D.rt(L));  % this is the inverse weight for the diffusion fit. I might be looking for variance instead.
    meanRT(i) = mean(D.rt(L)); % this is just for plotting
    semRT(i) = stderr(D.rt(L)); % this is just for plotting
end


%% 1.3 Fit the reaction times (RT) and predict choice
% Use the simple model to fit the RT using the selected trials from step 1.
% The free parameters are the bound _B_ , the coefficient $\kappa$, and a
% bias, expressed as an an offset in stimulus strength, _�_ (see assumption
% 2). The diffusion model explains the decision time, whereas the reaction
% time includes additional times that do not depend on stimulus strength.
% We refer to this as the non-decision time, and we allow for the
% possibility that this might be different for left and right choices,
% parameterized by the terms on the right side of
%
% $$t_{nd,ch=0} = t_{nd}$$
%
% $$t_{nd,ch=1} = t_{nd}+t_{nd,\Delta}$$
%
% The fitting function, |dtb_fit_means| has a variety of of options which
% are documented in the function. Here, we are telling the function to fit
% only the RT, which it does by minimizing the negative log likelihood of
% the RT.  Note that we use only the trials in which the choice is correct
% relative the bias (estimated in Step 1) and we calculate the log
% likelihoods assuming Gaussian noise, with expectation given by the model
% and a standard deviation derived from the data (Step 2). We then use the
% fitted parameters to predict the choice function, which is fully
% specified by _B_, $\kappa$ and _�_. The last term is a bias in units of
% stimulus strength. As a sanity check, it ought to approximate the value
% obtained from the logistic fit to choice in step 1.
%

[Dout,W,T_opt,T_opt_se,grad,hess,nlogl,Wpred]=dtb_fit_means(D,"rt_only",true,...
    "tnd_delta_opt",1,"mu_opt",1);
% Dout contains the original D structure plus the fit parameters and their standard error


%% 1.4 Fit both the reaction times and the choices
% Here we use the same RTs as in step 3, but we allow the choices to
% contribute to the log likelihood. The model provides the probability of a
% rightward and leftward choice given the strength on each trial. The
% likelihood of the actual choice (all trials)  is now included together
% with the likelihood of the RTs (selected trials) in the optimization.
%
% This typically provides a more reliable estimate of parameters, and it
% serves as a sanity check on the predicted choice function. The comparison
% of the RT fits from steps 3 and 4 also supply intuition about what is
% driving a fit (or a poor fit) to RT the more detailed models pursued
% below.
%
% Note that it is not possible to fit the choices to predict the RT because
% the former uses only a subset of the parameters for RT and, more
% importantly, the choice function depends on the product, $\kappa(C+\mu)B$. 
% Thus it is not possible to separate _B_ and $\kappa$.

[DbOut,Wb,~,~,~,~,~,WbPred]=dtb_fit_means(D,"rt_only",false,"tnd_delta_opt",1,"mu_opt",1);
 
% Here are the fit parameters and their s.e.
[DbOut.theta_opt" DbOut.theta_opt_se]
%   B           bound 
%   kappa       multiplier on strenghth to get drift
%   mu          strength bias
%   tnd         non decision time
%   tnd_delta   non decision time offset for positive strengths 


%% 1.5 Plot the data, fits and prediction
hFig = figure(); clf;
hax(1) = subplot(2,1,1); hold on
plot(theStrengths,pCh,"ko","markerfacecolor","k","MarkerSize",4);
xint =  linspace(min(theStrengths),max(theStrengths),100);
plot(xint,glmval(beta,xint,"logit"),"k-");
h = ylabel("Prob. positive choice");
set(h,"VerticalAlignment","bottom","fontsize",16);

hax(2) = subplot(2,1,2); hold on
[hsym,hxe,hye] = errorbar2(theStrengths,meanRT,semRT,semRT);
delete(hxe);
set(hsym,"markerfacecolor","k","MarkerSize",4);

set(hFig,"CurrentAxes",hax(1));
hPredCh = plot(Wpred.strength,Wpred.choice,"b-"); 

set(hFig,"CurrentAxes",hax(1));
hFitCh = plot(WbPred.strength,WbPred.choice,"r--");
set(hFig,"CurrentAxes",hax(2));
hFitRTonly = plot(Wpred.strength,Wpred.rt,"b-");
hFitRTboth = plot(WbPred.strength,WbPred.rt,"r--");

xlabel("Stimulus strength","fontsize",16);
ylabel("RT (s)","fontsize",16);
set(hax,"tickdir","out");
set(hax(1),"XTickLabel",[]);
ptop = get(hax(1),"position");
pbot = get(hax(2),"position");
set(hax(1),"position",[ptop(1), 0.1*pbot(4)+sum(pbot([2 4])),ptop([3 4])]);
set(hax,"xgrid","on");

% add legends
set(hFig,"CurrentAxes",hax(1));
[LEGH,OBJH,~,~]=legend("data","GLM","prediction","joint fit");
set(OBJH(1:4),"FontSize",14);
set(LEGH,"box","off");

set(hFig,"CurrentAxes",hax(2));
[LEGH,OBJH,OUTH,OUTM]=legend("","data","fit","joint fit");
set(OBJH(2:4),"FontSize",14);
set(OUTH(1),"visible","on");
set(LEGH,"box","off");
set(OBJH([5 6]),"visible","off");

%% Part 2. Diffusion with collapsing bounds
%%
% As noted earlier, the DDM with flat bounds is unable to account for
% different RT on correct and error trials, and it does not specify the
% observed shape of RT distribution. The introduction of collapsing bounds
% can explain both of these features of the data. This allows us to use
% maximum likelihood to estimate the model parameters because the model
% specifies the probability of observing a choice at time $T$ given the
% stimulus strength and model parameters, $\theta$. The latter include
% $\kappa$, the nonstationary bounds $\pm B(t)$, starting point $(y_0)$,
% bias in drift rate $(\mu)$, $t_{nd}$, $t_{nd,\Delta}$. $\sigma_{t_{nd}}$.
% Most of these terms are already familiar from the flat bound model. We
% did not make use of the starting point offset above. We did not need the
% standard deviation of the non-decision time, $\sigma_{t_{nd}}$, because
% we were working with means. Now we are trying to estimate the
% distribution of RT, which is the sum of two random variables. Assuming
% independence, the distribution is the convolution of the distribuutions
% of decision and non-decision times. The $\pm B(t)$ is typically
% represented by a few parameters (3 in the code below).
%
% To early mathematical psychologists, it seemed obvious that the extension
% of the absorbing markov chains, gambler"s ruin, sequential probability
% ratio test would invite the same flat bound (i.e. stationary bound)
% solution. It seemed justified on the grounds of parsimony and assumed
% optimality, although we have not seen this stated explicitly. However,
% this assumption led to early abandonment of the model because it was
% clear that for difficult decisions, the mean RT on errors was not
% identical to mean RT for the correct choices at the same stimulus
% strength. Link and Heath (1975) provided a possible resolution using
% non-gaussian increments, but this was not widely accepted. Donald Laming,
% who was an early champion of evidence accumulation to bound, abandoned
% these models completely (personal observation). 
%
% Whereas the simple DDM with flat bounds has analytic expressions for
% choice and mean RT, the collapsing bounds require numerical methods.
% There are three approaches. The most intuitive, but least useful is to
% simulate single diffusion paths using a set of parameters, assemble
% statistics on the simulated choices and RTs and compare them to real
% data. That is a useful exercise but we find it unreliable for fitting
% data. The other approaches involve propagating the probability
% distribution of the decision variable. This would be easy if there were
% no bounds?just a Normal distribution with time dependent mean and
% variance?but thorny because of the bounds. So the algorithms proceed step
% by step, to estimate the distribution the absorbed area at the upper and
% lower bounds and continue to propagate the odd looking distribution of
% unabsorbed probability another $\Delta t$. The two ways are to perform a
% convolution with a Normal distribution representing the momentary
% evidence or by propagating a partial differential equation
% (Fokker-Planck) that describes the same process.
%
% The methods are slow because they require small time steps. We recommend
% 1/20 of a ms (50,000 samples/s). This has to be done at every unique
% value of drift rate, which is typically the unique values of
% D.strength. If there is no bias, this can be cut in half, but we
% rarely fix the bias to zero.
%% 2.1 Read in the data
%
% You can use the data above, but it contains some extra fields that we
% appended. That"s okay, but all you need are the three fields(.strength,
%  .rt, .choice).

D.use_like=ones(size(D.choice)); % for collapse we use all choices for rt fit

%% 2.2 Set initial parameters
% We use a bounded search for the fit. We use T to establish the starting
% guess and range. Check to see if your fits are at the the extreme end of
% the range. If so, expand the range or rescale strength. Either way, don"t
% trust the fit!
clear T
T{1}.kappa=15;  T{2}.kappa=0.1;     T{3}.kappa=30;
T{1}.mu=.05;        T{2}.mu=-0.5;           T{3}.mu=0.5;
T{1}.B=0.5;     T{2}.B=0.05;        T{3}.B=2;
T{1}.Balpha=0.5;     T{2}.Balpha=0.01;        T{3}.Balpha=10;
T{1}.Bbeta=1;     T{2}.Bbeta=0.01;        T{3}.Bbeta=10;
T{1}.tnd=0.4;   T{2}.tnd=0.02;      T{3}.tnd=0.8;
T{1}.tnd_sd=0.05; T{2}.tnd_sd=0.005;    T{3}.tnd_sd=0.15;

options = optimset("fminsearch");
options.MaxFunEvals = 200; % comment out to do full optimization
% options =    optimoptions("fmincon","Algorithm","interior-point")

% next bit repackages structure T into jittered initial guess and upper and
% lower bounds in the format that fminsearch needs
[theta,theta_lo,theta_hi,P]=opt_pack(T,0.3);

%% 2.3 Optimize
% This will take some time, even with MaxFunEvals set to 200
[theta_opt, fval_fms] = fminsearchbnd(@(theta) cost_dtb_collapse(theta,P,D),theta,theta_lo,theta_hi,options);

[T_opt, D_opt]=opt_unpack(theta_opt,P); % return optimal parameters
%% 
% If you"re using the collapse_data, you can compare the fit (even the one
% that stopped prematurely) with the parameters used to generate the
% simulated data: 
%
% $$\{kappa, B, B_{\alpha}, B_{\beta}, t_{nd},t_{nd_{\sigma}}\}=\{10,1,.5,.5,.4,.05\} $$
%
%% 2.4 Use optimal params to get predictions
[nlogl,G1] = cost_dtb_collapse(theta_opt,P,D);
%%
% ALso get fit predictions at interpolated values (for plotting)

clear Dopt;
Dopt.strength=sort([-logspace(log10(0.032) ,log10(0.512) ,33) 0 logspace(log10(0.032) ,log10(0.512) ,33)])";
Dopt.choice=Dopt.strength>=0;
Dopt.corr=Dopt.strength>=0;
Dopt.rt=max(D.rt)*ones(size(Dopt.strength));

[nlogl,G1] = cost_dtb_collapse(theta_opt,P,Dopt);


%% 2.5 Plot

clf;
col="k";

subplot(2,2,1);
plot_psychometric(G1,"data",0,"rt",0,"col",col,"folded",0);
plot_psychometric(D,"pred",0,"rt",0,"col",col,"folded",0);

subplot(2,2,2)
plot_psychometric(G1,"data",0,"choice",0,"col",col,"folded",0);
plot_psychometric(D,"pred",0,"choice",0,"col",col,"folded",0);

subplot(2,2,3);
s=G1.Bup>0;
plot(G1.t,G1.Bup.*s);
hold on
plot(G1.t,-G1.Bup.*s);
title("Bounds");
xlabel("Time (s)");
ylabel("Accumulated Evidence");
shg

%% Fokker-Planck method
% I will write more about this. For now, this is simply an introduction to
% some useful but yet to be properly documented code. Actually, for now
% it"s a place holder; I"ve run out of time.






